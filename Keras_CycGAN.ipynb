{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K_CycGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoxregqz6S5c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_BA7wqX5oG3"
      },
      "source": [
        "## CycleGAN CT Generation\n",
        "# Graham Schloesser 08/13/21\n",
        "# Based on code from https://keras.io/examples/generative/cyclegan/\n",
        "\n",
        "This code was developed to generate synthetic CT images from MRI image inputs. To be able to run this code make sure the file paths are updated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mppf9hk5xWZi"
      },
      "source": [
        "pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytbVNxMuZNgF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS9bUCVO5mcL"
      },
      "source": [
        "# Adjust the following file paths\n",
        "example_filename_CT and MRI are paths to the individual scans for testing. Make sure that these two scans are paired data\n",
        "\n",
        "train_path_CT and MRI are a folder of multiple scans to train the model on. \n",
        "\n",
        "checkpoint path is where the model is saved\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXYmv2Ydrt1"
      },
      "source": [
        "example_filename_CT = '/content/drive/My Drive/GAN_IM/CT_Pair/020_Ax_T1_BRAVO_Stealth_CT.nii.gz'\n",
        "example_filename_MRI = '/content/drive/My Drive/GAN_IM/MR_Pair/020_Ax_T1_BRAVO_Stealth.nii.gz'\n",
        "train_path_MRI = '/content/drive/My Drive/GAN_IM/MR_Pair'\n",
        "train_path_CT = '/content/drive/My Drive/GAN_IM/CT_Pair'\n",
        "checkpoint_path = '/content/drive/MyDrive/GAN_IM/checkpoints'\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "OUTPUT_CHANNELS = 3\n",
        "BUFFER_SIZE = 250\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 512\n",
        "DEPTH = 232\n",
        "\n",
        "autotune = tf.data.experimental.AUTOTUNE\n",
        "# Weights initializer for the layers.\n",
        "kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "# Gamma initializer for instance normalization.\n",
        "gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "input_img_size = (512, 512, 3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPut8d6ieG5A"
      },
      "source": [
        "def random_crop(image):\n",
        "    cropped_image = tf.image.random_crop(image, size=[IMG_HEIGHT, IMG_WIDTH])\n",
        "    return cropped_image\n",
        "\n",
        "def normalize_MRI(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image / (tf.math.reduce_max(image))*2) - 1\n",
        "    #image = tf.image.resize(image,[256,256])\n",
        "    return image\n",
        "\n",
        "def normalize_CT(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image + abs(tf.math.reduce_min(image))\n",
        "    image = (image / (tf.math.reduce_max(image))*2) - 1\n",
        "    #image = tf.image.resize(image,[256,256])\n",
        "    return image\n",
        "\n",
        "def preprocess_MRI(image):\n",
        "    #image = random_jitter(image)\n",
        "    image = normalize_MRI(image)\n",
        "    return image\n",
        "def preprocess_CT(image):\n",
        "    #image = random_jitter(image)\n",
        "    image = normalize_CT(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def pipe_train(path,type):\n",
        "    threshold = 9\n",
        "    sample_limit = 0                    \n",
        "    for filename in os.listdir(path):  \n",
        "        if filename.endswith('.gz'):   \n",
        "          sample = nib.load(path + '/' + filename).get_fdata()\n",
        "          samp_shape = np.shape(sample)\n",
        "          size = math.floor(samp_shape[2]/3)\n",
        "          temp_array = np.zeros((size,samp_shape[0],samp_shape[1],3))\n",
        "          for i in range(size):\n",
        "              if type == 0:     #for MRI images\n",
        "                  temp_array[i,:,:,0:2] = preprocess_MRI(sample[:,:,i*3:(i*3)+2])\n",
        "              if type == 1:     #for CT images\n",
        "                  temp_array[i,:,:,0:2] = preprocess_CT(sample[:,:,i*3:(i*3)+2])\n",
        "\n",
        "          if sample_limit == 0:\n",
        "              combined_array = temp_array\n",
        "          else:\n",
        "              combined_array = np.append(combined_array,temp_array,axis=0)\n",
        "              \n",
        "\n",
        "          sample_limit = sample_limit + 1\n",
        "\n",
        "          if sample_limit >= threshold:\n",
        "            break\n",
        "\n",
        "    train_data = tf.data.Dataset.from_tensor_slices(combined_array)\n",
        "\n",
        "    tf_data = train_data.map(do_nothing, num_parallel_calls=AUTOTUNE).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "    return tf_data\n",
        "\n",
        "def do_nothing(image):\n",
        "    return tf.cast(image, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD33h-wde39p"
      },
      "source": [
        "train_MRI = None\n",
        "train_CT = None\n",
        "\n",
        "train_MRI = pipe_train(train_path_MRI,0)\n",
        "train_CT = pipe_train(train_path_CT,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v5k0b59kSDr"
      },
      "source": [
        "_, ax = plt.subplots(4, 2, figsize=(10, 15))\n",
        "for i, samples in enumerate(zip(train_MRI.take(4), train_CT.take(4))):\n",
        "    MRI = (((samples[0][0]+1.0)*127.5).numpy()).astype(np.uint8)\n",
        "    CT = (((samples[1][0]+1.0)*127.5).numpy()).astype(np.uint8)\n",
        "    ax[i, 0].imshow(MRI[:,:,0],cmap = 'gray')\n",
        "    ax[i, 1].imshow(CT[:,:,0],cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8swN-5QuwcUL"
      },
      "source": [
        "class ReflectionPadding2D(layers.Layer):\n",
        "    \"\"\"Implements Reflection Padding as a layer.\n",
        "\n",
        "    Args:\n",
        "        padding(tuple): Amount of padding for the\n",
        "        spatial dimensions.\n",
        "\n",
        "    Returns:\n",
        "        A padded tensor with the same type as the input tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, input_tensor, mask=None):\n",
        "        padding_width, padding_height = self.padding\n",
        "        padding_tensor = [\n",
        "            [0, 0],\n",
        "            [padding_height, padding_height],\n",
        "            [padding_width, padding_width],\n",
        "            [0, 0],\n",
        "        ]\n",
        "        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n",
        "\n",
        "\n",
        "def residual_block(\n",
        "    x,\n",
        "    activation,\n",
        "    kernel_initializer=kernel_init,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"valid\",\n",
        "    gamma_initializer=gamma_init,\n",
        "    use_bias=False,\n",
        "):\n",
        "    dim = x.shape[-1]\n",
        "    input_tensor = x\n",
        "\n",
        "    x = ReflectionPadding2D()(input_tensor)\n",
        "    x = layers.Conv2D(\n",
        "        dim,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    x = activation(x)\n",
        "\n",
        "    x = ReflectionPadding2D()(x)\n",
        "    x = layers.Conv2D(\n",
        "        dim,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    x = layers.add([input_tensor, x])\n",
        "    return x\n",
        "\n",
        "\n",
        "def downsample(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_initializer=kernel_init,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(2, 2),\n",
        "    padding=\"same\",\n",
        "    gamma_initializer=gamma_init,\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        filters,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        padding=padding,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def upsample(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(2, 2),\n",
        "    padding=\"same\",\n",
        "    kernel_initializer=kernel_init,\n",
        "    gamma_initializer=gamma_init,\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2DTranspose(\n",
        "        filters,\n",
        "        kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        use_bias=use_bias,\n",
        "    )(x)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXcuPOIIw0Lw"
      },
      "source": [
        "def get_resnet_generator(\n",
        "    filters=64,\n",
        "    num_downsampling_blocks=2,\n",
        "    num_residual_blocks=9,\n",
        "    num_upsample_blocks=2,\n",
        "    gamma_initializer=gamma_init,\n",
        "    name=None,\n",
        "):\n",
        "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
        "    x = ReflectionPadding2D(padding=(3, 3))(img_input)\n",
        "    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(\n",
        "        x\n",
        "    )\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    # Downsampling\n",
        "    for _ in range(num_downsampling_blocks):\n",
        "        filters *= 2\n",
        "        x = downsample(x, filters=filters, activation=layers.Activation(\"relu\"))\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(num_residual_blocks):\n",
        "        x = residual_block(x, activation=layers.Activation(\"relu\"))\n",
        "\n",
        "    # Upsampling\n",
        "    for _ in range(num_upsample_blocks):\n",
        "        filters //= 2\n",
        "        x = upsample(x, filters, activation=layers.Activation(\"relu\"))\n",
        "\n",
        "    # Final block\n",
        "    x = ReflectionPadding2D(padding=(3, 3))(x)\n",
        "    x = layers.Conv2D(3, (7, 7), padding=\"valid\")(x)\n",
        "    x = layers.Activation(\"tanh\")(x)\n",
        "\n",
        "    model = keras.models.Model(img_input, x, name=name)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-eqh1SqxEKG"
      },
      "source": [
        "def get_discriminator(\n",
        "    filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None\n",
        "):\n",
        "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
        "    x = layers.Conv2D(\n",
        "        filters,\n",
        "        (4, 4),\n",
        "        strides=(2, 2),\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=kernel_initializer,\n",
        "    )(img_input)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    num_filters = filters\n",
        "    for num_downsample_block in range(3):\n",
        "        num_filters *= 2\n",
        "        if num_downsample_block < 2:\n",
        "            x = downsample(\n",
        "                x,\n",
        "                filters=num_filters,\n",
        "                activation=layers.LeakyReLU(0.2),\n",
        "                kernel_size=(4, 4),\n",
        "                strides=(2, 2),\n",
        "            )\n",
        "        else:\n",
        "            x = downsample(\n",
        "                x,\n",
        "                filters=num_filters,\n",
        "                activation=layers.LeakyReLU(0.2),\n",
        "                kernel_size=(4, 4),\n",
        "                strides=(1, 1),\n",
        "            )\n",
        "\n",
        "    x = layers.Conv2D(\n",
        "        1, (4, 4), strides=(1, 1), padding=\"same\", kernel_initializer=kernel_initializer\n",
        "    )(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=img_input, outputs=x, name=name)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the generators\n",
        "gen_G = get_resnet_generator(name=\"generator_G\")\n",
        "gen_F = get_resnet_generator(name=\"generator_F\")\n",
        "\n",
        "# Get the discriminators\n",
        "disc_X = get_discriminator(name=\"discriminator_X\")\n",
        "disc_Y = get_discriminator(name=\"discriminator_Y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUe8tkdqxhsH"
      },
      "source": [
        "class CycleGan(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator_G,\n",
        "        generator_F,\n",
        "        discriminator_X,\n",
        "        discriminator_Y,\n",
        "        lambda_cycle=10.0,\n",
        "        lambda_identity=0.5,\n",
        "    ):\n",
        "        super(CycleGan, self).__init__()\n",
        "        self.gen_G = generator_G\n",
        "        self.gen_F = generator_F\n",
        "        self.disc_X = discriminator_X\n",
        "        self.disc_Y = discriminator_Y\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        self.lambda_identity = lambda_identity\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        gen_G_optimizer,\n",
        "        gen_F_optimizer,\n",
        "        disc_X_optimizer,\n",
        "        disc_Y_optimizer,\n",
        "        gen_loss_fn,\n",
        "        disc_loss_fn,\n",
        "    ):\n",
        "        super(CycleGan, self).compile()\n",
        "        self.gen_G_optimizer = gen_G_optimizer\n",
        "        self.gen_F_optimizer = gen_F_optimizer\n",
        "        self.disc_X_optimizer = disc_X_optimizer\n",
        "        self.disc_Y_optimizer = disc_Y_optimizer\n",
        "        self.generator_loss_fn = gen_loss_fn\n",
        "        self.discriminator_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n",
        "        self.identity_loss_fn = keras.losses.MeanAbsoluteError()\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        # x is Horse and y is zebra\n",
        "        real_x, real_y = batch_data\n",
        "\n",
        "        # For CycleGAN, we need to calculate different\n",
        "        # kinds of losses for the generators and discriminators.\n",
        "        # We will perform the following steps here:\n",
        "        #\n",
        "        # 1. Pass real images through the generators and get the generated images\n",
        "        # 2. Pass the generated images back to the generators to check if we\n",
        "        #    we can predict the original image from the generated image.\n",
        "        # 3. Do an identity mapping of the real images using the generators.\n",
        "        # 4. Pass the generated images in 1) to the corresponding discriminators.\n",
        "        # 5. Calculate the generators total loss (adverserial + cycle + identity)\n",
        "        # 6. Calculate the discriminators loss\n",
        "        # 7. Update the weights of the generators\n",
        "        # 8. Update the weights of the discriminators\n",
        "        # 9. Return the losses in a dictionary\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Horse to fake zebra\n",
        "            fake_y = self.gen_G(real_x, training=True)\n",
        "            # Zebra to fake horse -> y2x\n",
        "            fake_x = self.gen_F(real_y, training=True)\n",
        "\n",
        "            # Cycle (Horse to fake zebra to fake horse): x -> y -> x\n",
        "            cycled_x = self.gen_F(fake_y, training=True)\n",
        "            # Cycle (Zebra to fake horse to fake zebra) y -> x -> y\n",
        "            cycled_y = self.gen_G(fake_x, training=True)\n",
        "\n",
        "            # Identity mapping\n",
        "            same_x = self.gen_F(real_x, training=True)\n",
        "            same_y = self.gen_G(real_y, training=True)\n",
        "\n",
        "            # Discriminator output\n",
        "            disc_real_x = self.disc_X(real_x, training=True)\n",
        "            disc_fake_x = self.disc_X(fake_x, training=True)\n",
        "\n",
        "            disc_real_y = self.disc_Y(real_y, training=True)\n",
        "            disc_fake_y = self.disc_Y(fake_y, training=True)\n",
        "\n",
        "            # Generator adverserial loss\n",
        "            gen_G_loss = self.generator_loss_fn(disc_fake_y)\n",
        "            gen_F_loss = self.generator_loss_fn(disc_fake_x)\n",
        "\n",
        "            # Generator cycle loss\n",
        "            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle\n",
        "            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle\n",
        "\n",
        "            # Generator identity loss\n",
        "            id_loss_G = (\n",
        "                self.identity_loss_fn(real_y, same_y)\n",
        "                * self.lambda_cycle\n",
        "                * self.lambda_identity\n",
        "            )\n",
        "            id_loss_F = (\n",
        "                self.identity_loss_fn(real_x, same_x)\n",
        "                * self.lambda_cycle\n",
        "                * self.lambda_identity\n",
        "            )\n",
        "\n",
        "            # Total generator loss\n",
        "            total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G\n",
        "            total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F\n",
        "\n",
        "            # Discriminator loss\n",
        "            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)\n",
        "            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)\n",
        "\n",
        "        # Get the gradients for the generators\n",
        "        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n",
        "        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n",
        "\n",
        "        # Get the gradients for the discriminators\n",
        "        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n",
        "        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n",
        "\n",
        "        # Update the weights of the generators\n",
        "        self.gen_G_optimizer.apply_gradients(\n",
        "            zip(grads_G, self.gen_G.trainable_variables)\n",
        "        )\n",
        "        self.gen_F_optimizer.apply_gradients(\n",
        "            zip(grads_F, self.gen_F.trainable_variables)\n",
        "        )\n",
        "\n",
        "        # Update the weights of the discriminators\n",
        "        self.disc_X_optimizer.apply_gradients(\n",
        "            zip(disc_X_grads, self.disc_X.trainable_variables)\n",
        "        )\n",
        "        self.disc_Y_optimizer.apply_gradients(\n",
        "            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"G_loss\": total_loss_G,\n",
        "            \"F_loss\": total_loss_F,\n",
        "            \"D_X_loss\": disc_X_loss,\n",
        "            \"D_Y_loss\": disc_Y_loss,\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2viyoOfex_C3"
      },
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    \"\"\"A callback to generate and save images after each epoch\"\"\"\n",
        "\n",
        "    def __init__(self, num_img=4):\n",
        "        self.num_img = num_img\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        _, ax = plt.subplots(4, 2, figsize=(12, 12))\n",
        "        for i, img in enumerate(train_MRI.take(self.num_img)):\n",
        "            prediction = self.model.gen_G(img)[0].numpy()\n",
        "            prediction = ((prediction + 1.0) * 127.5).astype(np.uint8)\n",
        "            img = ((img[0] + 1.0) * 127.5).numpy().astype(np.uint8)\n",
        "\n",
        "            ax[i, 0].imshow(img[:,:,0],cmap='gray')\n",
        "            ax[i, 1].imshow(prediction[:,:,0],cmap='gray')\n",
        "            ax[i, 0].set_title(\"Input image\")\n",
        "            ax[i, 1].set_title(\"Translated image\")\n",
        "            ax[i, 0].axis(\"off\")\n",
        "            ax[i, 1].axis(\"off\")\n",
        "\n",
        "            prediction = keras.preprocessing.image.array_to_img(prediction)\n",
        "        plt.show()\n",
        "        plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk0mKC-GydeZ"
      },
      "source": [
        "# Loss function for evaluating adversarial loss\n",
        "adv_loss_fn = keras.losses.MeanSquaredError()\n",
        "#checkpoint_path = \"/content/drive/MyDrive/GAN_IM/checkpoints.{epoch:03d}\"\n",
        "# Define the loss function for the generators\n",
        "def generator_loss_fn(fake):\n",
        "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
        "    return fake_loss\n",
        "\n",
        "\n",
        "# Define the loss function for the discriminators\n",
        "def discriminator_loss_fn(real, fake):\n",
        "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
        "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
        "    return (real_loss + fake_loss) * 0.5\n",
        "\n",
        "\n",
        "# Create cycle gan model\n",
        "cycle_gan_model = CycleGan(\n",
        "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "cycle_gan_model.compile(\n",
        "    gen_G_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    gen_F_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    disc_X_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
        "    gen_loss_fn=generator_loss_fn,\n",
        "    disc_loss_fn=discriminator_loss_fn,\n",
        ")\n",
        "# Callbacks\n",
        "plotter = GANMonitor()\n",
        "checkpoint_filepath = \"./content/drive/MyDrive/GAN_IM/checkpoints.{epoch:03d}\"\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath\n",
        ")\n",
        "\n",
        "cycle_gan_model.fit(\n",
        "    tf.data.Dataset.zip((train_MRI, train_CT)),\n",
        "    epochs= 20,\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2acAlUdqFvNQ"
      },
      "source": [
        "mod = cycle_gan_model.gen_G\n",
        "\n",
        "mod.save(\"/content/drive/MyDrive/GAN_IM/checkpoints/Keras_Test2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBsr9_YTGVKp"
      },
      "source": [
        "gen = (\"/content/drive/MyDrive/GAN_IM/checkpoints/Keras_Test2\")\n",
        "model = keras.models.load_model(gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLMpahcJ1jPv"
      },
      "source": [
        "def pipe_test(path,type):\n",
        "    sample_limit = 0 \n",
        "    thresh = 1                    \n",
        "    if path.endswith('.gz'):  \n",
        "      sample = nib.load(path).get_fdata()\n",
        "      samp_shape = np.shape(sample)\n",
        "      temp_array = np.zeros((samp_shape[2],samp_shape[0],samp_shape[1],3))\n",
        "      #loads data and creates temparary array to store data\n",
        "      for i in range(samp_shape[2]-2):\n",
        "          if type == 0:     #for MRI images\n",
        "              temp_array[i,:,:,0:2] = preprocess_MRI(sample[:,:,i:i+2])\n",
        "          if type == 1:     #for CT images\n",
        "              temp_array[i,:,:,0:2] = preprocess_CT(sample[:,:,i:i+2])\n",
        "\n",
        "      if sample_limit == 0:\n",
        "          combined_array = temp_array\n",
        "      else:\n",
        "          combined_array = np.append(combined_array,temp_array,axis=0)\n",
        "          #appends the temparary array into array that holds all samples\n",
        "\n",
        "\n",
        "    train_data = tf.data.Dataset.from_tensor_slices(combined_array)\n",
        "    #creates tensorflow dataset from array\n",
        "\n",
        "    tf_data = train_data.map(do_nothing, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE)\n",
        "    #maps the data for training\n",
        "\n",
        "    return tf_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnUv4B1Sx2lj"
      },
      "source": [
        "example_filename_CT = '/content/drive/My Drive/GAN_IM/CT_Pair/030_Ax_T1_BRAVO_Stealth_CT.nii.gz'\n",
        "example_filename_MRI = '/content/drive/My Drive/GAN_IM/MR_Pair/030_Ax_T1_BRAVO_Stealth.nii.gz'\n",
        "test_MRI = pipe_test(example_filename_MRI,0)\n",
        "test_CT = pipe_test(example_filename_CT,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED8_Inf3XNec"
      },
      "source": [
        "i = 0\n",
        "for image_x, image_y in tf.data.Dataset.zip((test_MRI, test_CT)):\n",
        "  _, ax = plt.subplots(1, 3,figsize = (18,12))\n",
        "  pred = model(image_x)[0].numpy()\n",
        "  prediction = ((pred + 1.0) * 127.5).astype(np.uint8)\n",
        "  img = ((image_x[0] + 1.0) * 127.5).numpy().astype(np.uint8)\n",
        "  img1 = ((image_y[0] + 1.0) * 127.5).numpy().astype(np.uint8)\n",
        "\n",
        "  ax[0].imshow(img[:,:,0],cmap='gray')\n",
        "  ax[1].imshow(prediction[:,:,0],cmap='gray')\n",
        "  ax[2].imshow(img1[:,:,0],cmap='gray')\n",
        "\n",
        "  ax[0].set_title(\"Input image\")\n",
        "  ax[1].set_title(\"Translated image\")\n",
        "  ax[2].set_title(\"True CT image\")\n",
        "\n",
        "  ax[0].axis(\"off\")\n",
        "  ax[1].axis(\"off\")\n",
        "  ax[2].axis(\"off\")\n",
        "  if i == 229:\n",
        "    break\n",
        "  i = i + 1\n",
        "  plt.savefig('/content/drive/MyDrive/GAN_IM/Keras_20e2_Images/keras_50e_' + str(i) + '.png')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}